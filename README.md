# AI-Powered Learning Recommendation System

**Production-grade personalized learning recommendation engine with real-time serving, model training pipelines, and full observability.**

[![CI/CD](https://github.com/yourorg/learning-recommender/workflows/CI/badge.svg)](https://github.com/yourorg/learning-recommender/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üéØ Mission

Deliver sub-200ms P95 personalized recommendations that increase learner engagement (CTR, time-on-content) over popularity baselines, with full reproducibility, observability, and GitOps-ready deployment.

## üìä Success Metrics

- **Engagement Lift**: +15% CTR vs. popularity baseline
- **Latency**: P95 < 200ms (service-side)
- **Model Quality**: Precision@10 > 0.25, NDCG@10 > 0.40
- **Uptime**: 99.9% availability SLO

---

## üèóÔ∏è Architecture at a Glance

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Client    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ FastAPI      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  BentoML    ‚îÇ
‚îÇ   (SPA)     ‚îÇ      ‚îÇ  Gateway     ‚îÇ      ‚îÇ  Model      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ (Auth/Orch.) ‚îÇ      ‚îÇ  Server     ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ                     ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  PostgreSQL  ‚îÇ      ‚îÇ   Milvus    ‚îÇ
                     ‚îÇ  (Metadata)  ‚îÇ      ‚îÇ   (ANN)     ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Kafka     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Prefect    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   MLflow    ‚îÇ
‚îÇ  (Events)   ‚îÇ      ‚îÇ  (ETL/Train) ‚îÇ      ‚îÇ  (Registry) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Components:**
- **Retrieval**: Two-tower dense embeddings (TensorFlow Recommenders)
- **Ranking**: XGBoost re-ranker on top-K candidates
- **Serving**: BentoML model server + FastAPI orchestration layer
- **Storage**: PostgreSQL (metadata), Milvus (vectors), S3/MinIO (events/models)
- **Orchestration**: Prefect (ETL/training), Kubernetes (deployment)
- **Observability**: Prometheus + Grafana + OpenTelemetry

---

## üöÄ Quick Start (Local Dev in 30 Minutes)

### Prerequisites

- **Docker** 20.10+ with docker-compose
- **Python** 3.11+
- **Make** (optional, for convenience commands)

### 1. Clone & Environment Setup

```bash
git clone https://github.com/yourorg/learning-recommender.git
cd learning-recommender

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements-dev.txt
```

### 2. Start Local Infrastructure

```bash
# Brings up: Postgres, Kafka, MinIO, Milvus, Redis, MLflow
./scripts/dev_up.sh

# Wait ~30 seconds for all services to be healthy
docker-compose ps
```

### 3. Initialize Database & Generate Sample Data

```bash
# Run migrations
python scripts/init_db.py

# Generate sample dataset (1000 users, 500 items, 10K events)
python scripts/sample_data_generator.py --users 1000 --items 500 --events 10000 --seed 42

# Upload to object store
python scripts/upload_events_to_storage.py
```

### 4. Train Models

```bash
# Train retrieval model (two-tower embeddings)
python -m src.models.train_retrieval --epochs 10 --batch-size 256

# Build ANN index
python scripts/build_milvus_index.py

# Train ranking model
python -m src.models.train_ranking --epochs 20

# Models are logged to MLflow (http://localhost:5000)
```

### 5. Start API Server

```bash
# Start FastAPI gateway
uvicorn src.api.main:app --reload --port 8000

# In another terminal, start BentoML model server
bentoml serve src/bentoml_service.py:svc --reload
```

### 6. Test Recommendations

```bash
# Get recommendations for user
curl http://localhost:8000/recommend/user_123?k=10

# Post an event
curl -X POST http://localhost:8000/events \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user_123",
    "content_id": "content_456",
    "event_type": "view",
    "value": 1.0,
    "ts": "2025-10-10T12:00:00Z"
  }'
```

### 7. View Dashboards

- **MLflow**: http://localhost:5000
- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **API Docs**: http://localhost:8000/docs

### 8. Run Tests

```bash
# Unit tests
pytest tests/unit -v

# Integration tests (requires running services)
pytest tests/integration -v

# Load tests
k6 run tests/load/recommend_load_test.js
```

### 9. Cleanup

```bash
./scripts/dev_down.sh
```

---

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/          # CI/CD pipelines
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml          # Lint, test, build
‚îÇ       ‚îî‚îÄ‚îÄ cd.yml          # Deploy to staging/prod
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md     # System design & diagrams
‚îÇ   ‚îú‚îÄ‚îÄ RUNBOOK.md          # Incident response & operations
‚îÇ   ‚îú‚îÄ‚îÄ MAINTENANCE.md      # Retrain schedules & SLAs
‚îÇ   ‚îî‚îÄ‚îÄ API.md              # OpenAPI spec & examples
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/          # IaC for cloud resources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aws/            # EKS, RDS, S3, VPC
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gcp/            # GKE, CloudSQL, GCS
‚îÇ   ‚îú‚îÄ‚îÄ kubernetes/         # K8s manifests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base/           # Kustomize base
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ overlays/       # staging, production
‚îÇ   ‚îî‚îÄ‚îÄ helm/               # Helm charts
‚îÇ       ‚îî‚îÄ‚îÄ learning-recommender/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                # FastAPI gateway
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/     # Auth, logging, CORS
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py      # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieval/      # Two-tower TFRS model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ranking/        # XGBoost ranker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_retrieval.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_ranking.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/             # SQLAlchemy models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py      # Data schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/          # Prefect flows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_pipeline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ training_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ serving/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bentoml_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ search/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ milvus_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ faiss_index.py  # Fallback
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py      # Prometheus metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tracing.py      # OpenTelemetry
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ drift_detector.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ auth.py         # JWT validation
‚îÇ       ‚îú‚îÄ‚îÄ secrets.py      # Secrets manager
‚îÇ       ‚îî‚îÄ‚îÄ config.py       # Settings management
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ dev_up.sh
‚îÇ   ‚îú‚îÄ‚îÄ dev_down.sh
‚îÇ   ‚îú‚îÄ‚îÄ init_db.py
‚îÇ   ‚îú‚îÄ‚îÄ sample_data_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ build_milvus_index.py
‚îÇ   ‚îî‚îÄ‚îÄ upload_events_to_storage.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ load/
‚îÇ       ‚îî‚îÄ‚îÄ recommend_load_test.js
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ grafana/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboards/
‚îÇ   ‚îî‚îÄ‚îÄ prometheus/
‚îÇ       ‚îî‚îÄ‚îÄ rules/
‚îú‚îÄ‚îÄ frontend/               # Minimal SPA demo
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ app.js
‚îÇ   ‚îî‚îÄ‚îÄ styles.css
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ requirements-dev.txt
‚îú‚îÄ‚îÄ pyproject.toml          # Black, isort, flake8 config
‚îú‚îÄ‚îÄ .pre-commit-config.yaml
‚îú‚îÄ‚îÄ CODEOWNERS
‚îî‚îÄ‚îÄ README.md
```

---

## üîß Configuration

Environment variables (see `.env.example`):

```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/recommendations

# Object Storage
S3_ENDPOINT=http://localhost:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET=learning-events

# Milvus
MILVUS_HOST=localhost
MILVUS_PORT=19530

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000

# Auth
JWT_SECRET_KEY=your-secret-key-here
JWT_ALGORITHM=HS256

# Feature Store
REDIS_URL=redis://localhost:6379/0

# Model Config
EMBEDDING_DIM=128
TOP_K_RETRIEVAL=100
TOP_K_RANKING=10
```

---

## üß™ Testing Strategy

### Unit Tests
```bash
pytest tests/unit -v --cov=src --cov-report=html
```

### Integration Tests
```bash
# Requires docker-compose services running
pytest tests/integration -v -m "not slow"
```

### Load Tests
```bash
# Simulate 100 concurrent users
k6 run --vus 100 --duration 30s tests/load/recommend_load_test.js
```

**Pass Criteria:**
- Unit test coverage > 80%
- Integration tests pass with real services
- P95 latency < 200ms @ 100 concurrent users

---

## üö¢ Deployment

### Staging

```bash
# Build and push images
docker build -t your-registry/learning-rec-api:v1.0.0 -f Dockerfile .
docker push your-registry/learning-rec-api:v1.0.0

# Deploy via ArgoCD
kubectl apply -f infra/kubernetes/argocd/application-staging.yaml

# Or manual kubectl
kubectl apply -k infra/kubernetes/overlays/staging
```

### Production

```bash
# Terraform provision
cd infra/terraform/aws
terraform init
terraform plan -var-file=prod.tfvars
terraform apply -var-file=prod.tfvars

# Deploy with Helm
helm upgrade --install learning-rec infra/helm/learning-recommender \
  --namespace production \
  --values infra/helm/learning-recommender/values-prod.yaml

# Canary rollout (ArgoCD)
kubectl argo rollouts promote learning-rec-api -n production
```

---

## üìà Observability

### Metrics (Prometheus)
- `recommend_request_duration_seconds` (histogram)
- `recommend_success_total` (counter)
- `model_score_mean` (gauge)
- `model_drift_score` (gauge)

### Dashboards (Grafana)
- **Service Health**: Latency, error rate, throughput
- **Model Performance**: Score distribution, precision/recall trends
- **Infrastructure**: CPU, memory, disk, network

### Alerts
- P95 latency > 300ms for 5 minutes
- Error rate > 2% for 10 minutes
- Model drift score > threshold

### Tracing (OpenTelemetry)
Distributed traces for recommendation request flow.

---

## üîê Security

- **Authentication**: JWT bearer tokens (RS256)
- **Authorization**: RBAC for admin endpoints (`/admin/*`)
- **Secrets**: AWS Secrets Manager / HashiCrypt Vault
- **TLS**: All endpoints enforce HTTPS in production
- **PII**: User IDs hashed; logs scrubbed
- **Data Retention**: 90-day event retention; opt-out enforcement

---

## üîÑ Model Lifecycle

### Training Cadence
- **Retrieval Model**: Weekly (Sunday 2 AM UTC)
- **Ranking Model**: Daily (2 AM UTC)
- **Index Rebuild**: Daily after ranking retrain

### Rollback Procedure
```bash
# List model versions
mlflow models list --name retrieval_model

# Promote previous version to production
mlflow models update-model-version \
  --name retrieval_model \
  --version 42 \
  --stage Production

# Redeploy
kubectl rollout restart deployment/bentoml-server -n production
```

### Experiment Tracking
All training runs logged to MLflow:
- Hyperparameters
- Metrics (precision@10, recall@10, NDCG@10)
- Artifacts (model weights, plots)
- Tags (experiment_id, git_commit)

---

## üìö Documentation

- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)**: Deep dive into system design
- **[RUNBOOK.md](docs/RUNBOOK.md)**: Incident triage & troubleshooting
- **[MAINTENANCE.md](docs/MAINTENANCE.md)**: Retrain schedules, backups, DR
- **[API.md](docs/API.md)**: OpenAPI spec & usage examples

---

## ü§ù Contributing

1. Create feature branch: `git checkout -b feature/amazing-feature`
2. Run pre-commit hooks: `pre-commit install && pre-commit run --all-files`
3. Write tests: `pytest tests/unit/test_your_feature.py`
4. Commit: `git commit -m "feat: add amazing feature"`
5. Push & open PR: `git push origin feature/amazing-feature`

See [CODEOWNERS](CODEOWNERS) for review assignments.

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file.

---

## üôå Acknowledgments

Built with reverence for legacy workflows and a forward-thinking approach to modern ML systems. Iterate fast, ship small, scale with confidence.

**Tech Stack Love**:
- TensorFlow Recommenders, PyTorch, XGBoost
- FastAPI, BentoML, Prefect
- Kubernetes, ArgoCD, Terraform
- Prometheus, Grafana, OpenTelemetry
- PostgreSQL, Milvus, Redis, Kafka

---

**Questions?** Open an issue or reach out to the platform team.

**First deployment?** Read the [30-minute onboarding guide](docs/ONBOARDING.md).
